# 开题调研阶段
日期：2024-03-09

姓名：丁孝航宇
## 工作内容：

- 阅读论文 Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning？
    - 这篇论文介绍了一种基于Transformer的漏洞检测系统,可以在代码编辑时(EditTime)即时检测到代码中的潜在漏洞。主要内容和技术路线如下:
    
    - 数据收集和预处理
        
        - 从GitHub公开仓库运行CodeQL静态分析器,收集含有250多种不同漏洞类型的代码片段
        - 将收集到的代码片段划分为上下文代码(context)和漏洞代码块(vulnerable block)两部分
        - 通过在代码块中随机分割,模拟代码编辑时的不完整状态
        
    - 模型架构和训练
    
        - 探索了三种学习方法应用于预训练语言模型:
            - a) Zero-shot: 使用prompt直接让模型判断给定代码是否有漏洞
                - 在论文中,Zero-shot学习的实现方式是通过设计prompt来指示预训练语言模型执行漏洞检测任务。具体步骤如下:
                    - 选择预训练语言模型
                        论文使用了两种预训练模型:code-davinci-002和text-davinci-003。前者是专门在源代码数据上预训练的,后者则是一个通用的基于InstructGPT架构的大模型。
                    - 生成任务描述prompt
                        首先通过让模型自身定义"漏洞检测任务"来获得一个任务描述prompt。例如对于code-davinci-002,通过多次提示"#We run CodeQL security queries in order to"获得诸如"identify potential security vulnerabilities"、"find security vulnerabilities"等多个描述。
                    - 构建输入prompt模板
                        将上面获得的任务描述与要检测的代码片段拼接成一个prompt模板,例如:
                        `<phrase>`
                        `<comment>Code snippet` 
                        `<code snippet>`
                        `<comment>Answer (Yes/No, explanation):`
                    - 模型推理
                        将构建好的prompt输入给预训练模型,模型会生成一个"Yes"或"No"的答复,同时还会给出一个解释性的文本。根据答复中是否包含"Yes"来判断该代码片段是否存在漏洞。
                        这种Zero-shot学习的方式不需要任何监督微调,只需要一个合理设计的prompt来指导模型执行漏洞检测任务。其优点是方便快捷,但缺点是性能可能不如经过监督微调的模型
            - b) Few-shot: 在zero-shot的基础上加入少量示例输入输出对
                - 论文中的Few-shot学习方式是在Zero-shot学习的基础上,为预训练语言模型提供少量的示例输入输出对。具体实现步骤如下:
                    - 使用Zero-shot时的最佳prompt模板
                        论文沿用了Zero-shot时表现最好的prompt模板格式,如对code-davinci-002使用:
                        `<phrase>  
                        <comment>Code snippet`
                        `<code snippet>`
                        `<comment>Answer (Yes/No, explanation):`
                    - 构建示例输入输出对
                        在上述prompt模板前面,增加若干个漏洞代码示例和非漏洞代码示例的输入输出对。这些示例遵循同样的prompt格式。
                    - 添加待检测代码
                        在包含示例的prompt后面,再次使用prompt模板的格式,添加需要检测的代码片段。
                    - 模型推理
                        将构建好的包含示例的prompt输入给预训练模型,模型会生成"Yes"或"No"的答复,根据答复判断代码是否存在漏洞。例如对于待检测代码C,一个可能的Few-shot prompt是:
                        `<示例1的prompt+输出>`
                        `<示例2的prompt+输出>`
                        `...`
                        `<phrase for C>`
                        `<comment>Code snippet for C`
                        `<code snippet for C>` 
                        `<comment>Answer (Yes/No):`
                        Few-shot学习的好处是能为模型提供一些监督示例,以期望模型能更好地理解和学习任务。但需要人工构造高质量的输入输出示例对,成本较高。
            - c) Fine-tuning: 在CodeBERT、code-davinci-002等预训练模型上进行微调
                - 论文中对于Fine-tuning的实现方式如下:
                - 选择预训练模型
                    作者使用了CodeBERT这个在源代码和自然语言双模态数据上预训练的Transformer模型。
                - 构建分类模型，在CodeBERT的基础上增加一个二分类头,将输入的<context, vulnerable_block>对映射为0(非漏洞)或1(漏洞)两个类别。
                - 准备训练数据，利用前面提到的数据预处理步骤,从带有漏洞标注的代码库中构建出<context, vulnerable_block, label>的训练三元组数据。
                - 模型训练，以监督学习的方式,使用构建的训练数据对CodeBERT及其分类头进行微调(fine-tune),目标是最小化分类误差。
                - 模型推理，对于一个新的<context, vulnerable_block>输入对,将它输入到微调后的模型,模型会输出一个0或1的预测标签,从而判断该代码块是否存在漏洞。
                - 除了在CodeBERT上进行分类的Fine-tuning方式,论文还提到了另一种Fine-tuning方式:使用code-davinci-002这种基于Encoder-Decoder的语言模型，将<context, vulnerable_block>拼接作为输入prompt，模型会自动生成一段后续token，根据生成token的内容(是否涉及漏洞关键词)来判断是否存在漏洞
                - 总的来说,Fine-tuning的优点是可以利用大量监督训练数据来指导模型学习漏洞模式,潜在地获得更好的性能表现,但需要大量的训练数据和计算资源。
    
    - 模型评估
    
        - 论文中对模型进行了三个方面的评估，评估指标包括精确率(Precision)和召回率(Recall):
    
        - Precision(精确率):表示预测的正确性，并计算为真阳性/(真阳性+ 假阳性) 
    
            Recall(召回率):表示预测的有效性，并计算为真阳性/(真阳性+ 假阴性)
    
        - 在自建数据集上评估三种策略下的模型性能：作者首先在自建的500K+编码漏洞数据集上,对Zero-shot、Few-shot和Fine-tuning三种策略下的6种模型变体进行了评估。主要结果如下:
    
            - 在CodeBERT上进行Fine-tuning的DeepDevVuln模型表现最佳,精确率59%,召回率63%。
            - Zero-shot和Few-shot在text-davinci-003大模型上表现次佳,召回率分别为78%和75%,但精确率较低(47%和49%)
    
        - 在公开数据集上与其他方法对比：作者在4个公开的代码漏洞检测基准数据集上,将DeepDevVuln模型与其他最新方法进行了对比:
    
            - 在MCP-Bench和VDisc数据集上,DeepDevVuln的F1分数最高
            - 在VuBD和VulDeePecker数据集上,DeepDevVuln的Recall最高,比最新工作提升10%
    
        - 评估在自动生成代码场景下的表现，为评估模型在自动生成代码中检测漏洞的能力,作者扩展了之前的CodeXGlue基准测试集，包含20种常见代码场景模板
    
            - 使用code-davinci-002完成每个场景的代码，统计生成的代码中包含漏洞的比例作为基线(40%)
    
            - 使用DeepDevVuln过滤后,漏洞率降低到4%,降幅90%
    
                

## 遇到的问题：

- 今日遇到的问题：
    
    - 本文探讨了如何基于LLM在代码编辑时(EditTime)即时检测代码中的潜在漏洞，而这与我们目前的设想（检测编写好的代码、开源软件中的代码漏洞）尚有一定区别，如何根据文章中技术迁移解决我们的设想
    
      

## 未来计划：



- 阅读论文调研相关技术背景，学习如何实现相关技术、训练模型