# 开题调研阶段
日期：2024-03-08

姓名：朱熠杭
## 工作内容：

- 前期预备工作:阅读论文，了解相关技术原理

  - 主要阅读[[2306.01754\] Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?](https://arxiv.org/abs/2306.01754)这篇论文

  - 该篇论文主要集中研究**大模型在代码实时编写中漏洞检测的表现，并且探讨了零次学习，少量学习和微调三种不同学习方法的效果**。主要表现为三大贡献：

  	1. 毫秒级识别不完整代码片段中的漏洞，以应用于edittime实时监测
  	2. 探讨了零次学习，少量学习和微调三种不同学习方法的效果
  	3. 扩展了Pearce等人引入的基准，将其作为未来edittime基准提供给社区
  
  - 数据集：
  
  	1. **数据集来源**：由GitHub LGTM服务在公共GitHub存储库中检测到的易受攻击的代码模式
  	2. **数据集内容**：漏洞类型，漏洞详细错误信息
  	3. **预处理方式**：三元组，包含上下文的代码片段、有漏洞的代码块和漏洞类型标签
  
  - 模型构建：在三个预训练模型上使用三种不同学习方法来搭建了共六个模型变体
  
  	1. **零次学习**：提供一个预先训练的模型，并提供一个指定我们期望输出的prompt
  	2. **少量学习**：在零次学习的基础上，除了prompt外，还提供示例输入-输出对
  	3. **微调**：在主干上增加一个线性分类头，建立一个多类分类模型
  
  - 模型评估：评估标准有三类
  
  	1. **准确率**：表示预测准确性，计算为真阳性/（真阳性+假阳性）
  
  	2. **召回率**：表示预测有效性，计算为真阳性/（真阳性+假阴性）
  
  	3. **F1-score**：准确率和召回率之间的平衡，定义为两者的集合平均值
  
  		
  
  - 实验结果：微调模型表现最好，允许在不产生高推理成本的情况下做出准确的预测，但也同时需要额外的维护以包括最新漏洞类型。我们可以利用该结论，对开源模型微调进行开发。
  
  	
  
  	
## 遇到的问题:

- 今日遇到的问题：
	- 对相关技术已经有一定程度了解了，但具体实践和架构还未尝试，实战该如何进行
	- 其实大模型训练总体路径都大差不差，我们是否可以在各个节点做出一些创新点？

## 未来计划：

- 继续阅读代码漏洞相关文章