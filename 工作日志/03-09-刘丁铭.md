# 开题调研阶段
日期：2024-03-09

姓名：刘丁铭
## 工作内容：

- 阅读论文 Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning？
    - 该论文介绍了一个基于tansformer的漏洞检测系统，实现了实时编辑代码时的漏洞检测功能。以下针对该系统的模块分别叙述
      - 数据收集：
        - 数据集包括7种语言。（JS、Python、Go、Java、C++、C#、ruby）
        - 有相应漏洞的CWE类别、详细错误信息以及问题开始和结束的行列位置。
      - 数据预处理：
        - 预处理目标：合成（c v l）三元组，分别表示上下文、易受攻击代码以及漏洞标签。
        - 预处理步骤：代码转AST -- 上下文与脆弱块分割 -- 分配标签 -- 85/5/10。
      - 模型架构
        - Zero-shot Learning：提供预训练模型，该模型包含所需输出的提示。
          - 提示预训练模型定义漏洞检测任务。提示模型"We run CodeQL security queries in order to"四次，获取最佳结果。这将产生以下提示变体"identify potential security vulnerabilities", "find potential security issues", "find security vulnerabilities", and "detect security vulnerabilities"
          - 设置相应的提示模板。
          - 检查模型响应中是否存在"yes" / "No"。
        - Few-shot Learning：相对于Zero-shot，可以提供少量的实例输入-输出来构建样本学习。
          - 构建相应的提示模板。该项目中依然选择了Zero-shot中的最优提示变体。
          - 构建示例输入输出对。对于每一个漏洞和语言类型的映射，提供包含<漏洞名称>和代码片段的实例，同样符合上述模板。
          - 对于每个漏洞和语言对，提供上述模板的样本三次，收获150个易受攻击的代码片段。
          - 提示模型"Provide an example in '<Language>' of a code snippet. Output the code only, do not include text:"以检索不易受攻击的代码。
          - 手动评估。
        - Fine-tuning：关注预训练的LLM模型、fine-tune CodeBERT、code-davinci-002。
          - 对于CodeBERT，在其BERT主干中添加了一个线性分类头，构建一个多累分类模型。
            - 输入结构：[BOS] 上下文代码 [SEP] 易受攻击代码 [EOS]。
            - 数据问题处理：易受攻击代码和不易受攻击代码的分布大约为1:9，因此每一轮训练保留易受攻击代码，轮换不易受攻击代码。
            - 采用标准二元交叉熵损失进行训练。
          - 对于codedavinci-002，基于训练集中的3w随机采样样本。
            - 输入结构：该模型可以不分类 
            - 输出：[BOS] c v [CLS][VULN]
      - 模型评估
    - 相关的内容：
      - code-davinci-002：Codex型号，擅长将自然语言翻译为代码，补全代码，插入补全
      - text-davinci-003：与gpt3.5一代的模型
      - CodeBERT：2020的老登，双峰预训练模型（PL、NL）
## 遇到的问题：


## 未来计划：