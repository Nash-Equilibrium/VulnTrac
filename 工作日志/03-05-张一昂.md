# 开题调研阶段
日期：2024-03-05

姓名：张一昂
## 工作内容：

- 调研任务
    - 查看arxiv，发现一篇文章较为契合：[InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://arxiv.org/abs/2403.02691)。
    - 文章[仓库地址](https://github.com/uiuc-kang-lab/InjecAgent)
    - 最近的工作将大语言模型具体化为代理，允许他们访问工具、执行操作以及与外部内容（例如电子邮件或网站）交互。然而，外部内容引入了间接提示注入 (IPI) 攻击的风险，其中恶意指令嵌入到 LLM 处理的内容中，旨在操纵这些代理对用户执行有害操作。鉴于此类攻击可能造成严重后果，建立评估和减轻这些风险的基准势在必行。
    - 在这项工作中，我们引入了 InjecAgent，这是一个旨在评估工具集成的 LLM 代理对 IPI 攻击的脆弱性的基准。InjecAgent 包含 1,054 个测试用例，涵盖 17 种不同的用户工具和 62 种攻击者工具。我们将攻击意图分为两种主要类型：对用户的直接伤害和私人数据的泄露。我们评估了 30 种不同的 LLM 代理，结果表明这些代理容易受到 IPI 攻击，其中 ReAct 提示的 GPT-4 在 24% 的情况下容易受到攻击。对增强设置的进一步调查显示，攻击者指令通过黑客提示得到加强，成功率进一步提高，ReAct 提示的 GPT-4 上的攻击成功率几乎翻了一番。我们的研究结果对大语言模型代理的广泛部署提出了质疑。
    - ![逻辑结构](https://github.com/uiuc-kang-lab/InjecAgent/blob/main/asset/overview.png?raw=true)
    - 对我们来讲，下一步的进展方向可以从:
    1. 大模型自身的安全和隐私性出发（例如本篇文章所涉及到的间接性注入攻击）
    1. 大模型如果应用于代码漏洞检测和入侵检测方向，最终的成品效果和质量。（是否仅仅是基于大模型作为识别的关键功能实现？如果是那样的话，我们整体项目的质量和工作量是否有限？）
## 遇到的问题:

- 开源大模型选择？
- 数据集来源？
- 公开数据集怎么样去做垂直领域的细化和调优？我们能否针对性地去收集系统开发所需要的数据？
## 未来计划：
- oop语言学习
- 大模型技术入门