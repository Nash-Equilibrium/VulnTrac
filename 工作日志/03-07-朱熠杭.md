# 开题调研阶段
日期：2024-03-07

姓名：朱熠杭
## 工作内容：

- 前期预备工作:阅读论文，了解相关技术原理

  - 主要阅读了百度旗下一篇文章：[大模型在代码缺陷检测领域的应用实践](https://mp.weixin.qq.com/s/kXSiXfgsezfLZjR-cGb5vg)

  - 该文章主要讲的是**LLM在SA中做出的贡献以及应用实践**。静态代码扫描(SA)能快速识别代码缺陷，如空指针访问、数组越界等，以较高ROI保障质量及提升交付效率。当前扫描能力主要依赖人工经验生成规则，泛化能力弱且迭代滞后，导致漏出。本文提出基于代码知识图谱解决给机器学什么的问题，以及基于代码大模型解决机器怎么学的问题。以期达到更小的人力成本，更好的效果泛化和更高的问题召回。

  - 常规SA的两大痛点：

  	1. 每种规则都需人工根据经验和后续的漏出分析维护，成本较高；以空指针场景为例，人工编写的规则代码共4439行，维护的回归case共227个，但Q2仍有3个bug漏出。我们**如何引入大模型减少开发成本，提质增效？**
  	2. 有效率偏低，扫描的能力有限(如断链、框架保证非空、复杂场景静态很难识别等，且风险的接受不同，扫描的部分高风险问题存在修复意愿低，对用户造成打扰。我们**如何通过模型，从历史误报中学习经验，进行过滤，减少打扰，提升召回？**
  
  - **代码知识图谱提取片段**：由于token数量有限制，我们需对代码进行缩减
  
  	- 构建被分析代码的知识图谱
  	- 目标变量检测识别：在变更代码中识别目标变量，作为待检测变量
  	- 变量依赖分析：基于控制流和数据流的与目标变量相关的依赖变量分析
  	- 特征语句提取和剪枝
  
  - 大模型进行代码检测两种主要方法
  
  	1. **判别式方法**，识别是否有缺陷以及缺陷类型
  
  		采用BERT进行缺陷检测共含3步，分别是预训练、微调和推理。
  
  		- 预训练阶段采用开源的多语言大模型，已较好的学习多种程序语言的语义。
  		- 微调阶段，给模型输入上述通过代码知识图谱提取的变量使用点相关的切片，以及是否有缺陷或者缺陷类型的标签，生成微调模型，让机器具备做检测任务的能力。输入的格式:
  
  		```
  		 { "slices": [{"line":"行代码内容", "loc": "行号"}]， "mark": {"label":"样本标签", "module_name"："代码库名", "commit_id"："代码版本", "file_path"："文件名", "risk_happend_line"："发生异常的行"} }
  		```
  
  		- 推理阶段，分析使用点目标变量的相关切片，通过微调模型进行预测，得到使用点是否有缺陷，以及缺陷类型
  
  			![图片](https://mmbiz.qpic.cn/mmbiz_png/5p8giadRibbOicf6FxWzLu277edD6hxKF5Mib0Ma3cN8U5kPdhIWCtTJ9xl0ibUDTwe0WyMWPdNPE7GbiaoRicX6yOnIw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
  
  	2. **生成式方法**，构建prompt，让程序自动扫描所有相关缺陷
  
  		生成式模型，闭源的如chatgpt、文心一言，有开源的如llama、bloom和starcode等。我们主要尝试文心一言、llama和bloom，**通过prompt(few shot、引入思维链、指定抽象的引导规则)和微调的方式**，探索模型在空指针缺陷检测的预测效果。整体f1测度不高，最佳的bloom61.69%，相比Bert路线的80%有差距，且模型的稳定性较差。因生成式路线有自身的优势，**如参数量大存在智能涌现具有更强的推理能力，允许输入的token量不断增加可减少对切片清洗的依赖，可与修复一起结合**等，我们预判在缺陷检测场景生成式是个趋势，接下来我们将继续优化，不断尝试prompt和微调，通过更合适的引导，更好的激发模型的潜力，从而提升生成式方法在检测场景的效果。
## 遇到的问题:

- 今日遇到的问题：
	- 对相关技术已经有一定程度了解了，但具体实践和架构还未尝试，实战该如何进行
	- 其实大模型训练总体路径都大差不差，我们是否可以在各个节点做出一些创新点？

## 未来计划：

- 继续阅读代码漏洞相关文章