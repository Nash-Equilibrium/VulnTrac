# 开题调研阶段
日期：2024-03-05

姓名：朱熠杭
## 工作内容：

- 前期预备工作:关注了大模型代码检测和修复这一块内容
	- 找到了一篇很不错的文章，是腾讯自研混元大模型用于代码漏洞检测和修复，这文章详细介绍了安全领域大模型的需求，以及大模型用于漏洞检测的开发过程，从数据收集，prompt工程，结果测评迭代都进行了介绍，最终是做出了一个vscode的插件，对我们开发相关方向具有非常大的借鉴价值，强烈推荐这篇文章！！！以下是链接：
	
	- [腾讯混元大模型在研发安全漏洞修复的实践](https://mp.weixin.qq.com/s/KwyuQPmInzXwqWjV46OmhQ)
	
	- 以下是一些重要内容引用：
	
	- > 利用传统方法做漏洞修复提效，只适用于比较简单的场景，比如根据版本号判断使用的开源组件是否存在漏洞，更多高危险的如导致数据泄露的注入类漏洞/账密类等，该方案难以通用。主要原因总结如下：
		>
		> 1. **规则限制：**传统静态分析技术通常基于预定义的规则和模式进行漏洞检测和修复，无法覆盖所有的漏洞类型和场景；
		> 2. **上下文和语义理解限制：**传统静态分析技术通常难以理解代码的上下文和语义信息，导致无法准确地理解代码的含义和逻辑；
		> 3. **创造性限制：**传统静态分析技术通常只能分析已有的代码，无法创造新的代码片段来修复漏洞，限制了漏洞修能力。
		>
		> **相比传统程序分析技术，大模型具备强大的推理能力，尤其是在代码生成方面表现突出，可通过训练来学习漏洞修复的模式和规律。**
	
		> #### 2.2 大模型代码生成能力
		>
		> **各类基座大模型和代码类Codex大模型，具有强大的代码生成能力。**这些模型可以理解自然语言指令，并根据这些指令生成相应的代码。这种能力使得它们可以用于各种编程任务，包括但不限于编写新的函数、修复代码中的错误、优化现有代码等。这些模型的代码生成能力基于其在大量代码库上的训练。在训练过程中，模型学习了各种编程语言的语法和语义以及如何将自然语言指令转化为代码。因此，只要给出清晰的指令，这些模型就能生成相应的代码。但这些生成的代码中仍存在一些安全问题，即：潜在的不正确、含漏洞的代码等。因此，我们需要利用大模型的代码生成能力，同时希望通过精调等操作，使大模型能有效修复漏洞代码，尽量生成安全无漏洞的代码片段。
		>
		> #### 2.3 大模型在安全防护领域的应用已成为趋势
		>
		> 2023年，大模型成为了各行各业的热门关注点，其中安全垂类领域的安全大模型也呈现了百花齐放的态势，主要覆盖安全咨询、安全培训、安全监控、安全修复等能力。微软2023年3月份正式发布集成GPT-4的Microsoft Security Copilot，旨在更好地提供安全工具和专家知识，辅助企业识别和检测安全风险。谷歌2023年4月发布“谷歌云AI安全工作台”，利用 Sec-PaLM 来帮助用户查找、总结和应对安全问题。国内公司也推出了自己独有的安全大模型，主要对于安全场景，提供专家级别的咨询建议，提效运营效率。
	
		![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvatQfruSdUnrxyDl4Z2DX0KkvwSDU2ADribufZmGDl1yTx428BCgrQcEYlXmUQ9pZWuicMiaibbVDr0y8A/640?wx_fmt=png&from=appmsg&wxfrom=5&wx_lazy=1&wx_co=1)
	
		如果要做代码检测和修复这个方向，我觉得是非常好的参考
## 遇到的问题:

- 今日遇到的问题：
	- 已经有较为成熟的商业产品出台，就比如这个已经有tx做了，我们是否能从中做出创新点来？？

## 未来计划：

- 其他方向还得看有没有比较好的思路